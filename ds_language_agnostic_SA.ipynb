{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds_Language_agnostic_SA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmuy94E02Agt",
        "colab_type": "text"
      },
      "source": [
        "## Language agnostic sentiment analysis using mean embedding vectors.\n",
        "Given a comment in any language, the polarity of the sentiment expressed is determined as follows:\n",
        "\n",
        "1.   The given comment is translated into english.\n",
        "2.   Each word in the translated comment is represented by a d-dimensionsal embedding vector.\n",
        "1.   The mean of the embedding vectors of relevant words in the comment is computed.\n",
        "2.   The mean embedding vector is used to as input to a pre-trained classifier to determine the sentiment polarity expressed by the comment.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDHIqe8D2gt5",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NWvg7j02o8O",
        "colab_type": "code",
        "outputId": "1146bbe7-2deb-486b-d9ad-4931074a4bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "! pip install googletrans\n",
        "import pandas as pd # for data handling\n",
        "import numpy as np # for linear algebra\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "from googletrans import Translator # for translation\n",
        "from gensim.models import KeyedVectors # for pre-trained embedding\n",
        "import tensorflow as tf # for neural network classifier\n",
        "from sklearn.manifold import TSNE # to display comments in 2D plot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/d6/e7/a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfXI6PvM20ph",
        "colab_type": "text"
      },
      "source": [
        "## Define function for translating comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM1D151i3A4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use google traslator\n",
        "translator = Translator()\n",
        "def translate(comment):\n",
        "  \"\"\"returns comment translated into english\"\"\"\n",
        "  return translator.translate(comment).text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "989nDi-o4PKc",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained word2vec model for embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP7C9s6n4gGR",
        "colab_type": "code",
        "outputId": "bef8eb8a-870d-4101-ed80-adfe45dfac8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Retrieve embedding file using wget\n",
        "# use this if embedding file is not available locally\n",
        "URL = \"https://s3.amazonaws.com/dl4j-distribution/\" # source url\n",
        "FILE = \"GoogleNews-vectors-negative300.bin.gz\" # source file name\n",
        "SOURCE = URL+FILE # source for embedding file\n",
        "DIR = \"/root/input/\" # directory\n",
        "! wget -P \"$DIR\" -c \"$SOURCE\" # retrieve embedding file\n",
        "\n",
        "# Load pre-trained word2vec model from embedding file\n",
        "EMBEDDING_FILE = DIR + FILE \n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "# Define vocabulary and embedding_size\n",
        "vocabulary = set(word2vec.index2word) # set of words in vocabulary\n",
        "embedding_size = word2vec.vector_size # dimension of word vector\n",
        "print(\"Model contains %d words\" %len(vocabulary))\n",
        "print(\"Each word is represented by a %d dimensional vector\" %embedding_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-05 12:20:55--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.110.181\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.110.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  36.0MB/s    in 44s     \n",
            "\n",
            "2019-06-05 12:21:40 (35.5 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n",
            "Model contains 3000000 words\n",
            "Each word is represented by a 300 dimensional vector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq6OZk1IpLgF",
        "colab_type": "text"
      },
      "source": [
        "Examine embedding vectors of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd4bKPc6mlYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "50e1a129-3c6f-495a-e555-364861545b31"
      },
      "source": [
        "word = input(\"Type in a word:\")\n",
        "print()\n",
        "if word not in vocabulary:\n",
        "  print(\"\\The word %s is not in the volcabulary\" %word)\n",
        "else:\n",
        "  print(\"%s is is respresented by the %d dimensional embedding vector:\\n\"\n",
        "       %(word, embedding_size))\n",
        "  print(', '.join([str(v)[:5] for v in word2vec[word.lower()].tolist()]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type in a word:great\n",
            "\n",
            "great is is respresented by the 300 dimensional embedding vector:\n",
            "\n",
            "0.071, 0.208, -0.02, 0.178, 0.132, -0.09, 0.096, -0.11, -0.00, 0.148, -0.03, -0.18, 0.041, -0.08, 0.021, 0.069, 0.180, 0.222, -0.10, -0.06, 0.000, 0.160, 0.040, 0.073, 0.153, 0.067, -0.10, 0.041, 0.042, -0.11, -0.06, 0.041, 0.25, 0.212, 0.159, 0.014, -0.04, 0.013, 0.003, 0.209, 0.152, -0.07, 0.216, -0.05, -0.02, -0.00, 0.152, -0.02, 0.021, -0.15, 0.104, 0.318, -0.18, 0.036, -0.11, -0.03, -0.10, -0.12, 0.322, -0.07, -0.15, 0.267, -0.15, -0.12, 0.107, 0.066, -0.02, -0.10, -0.20, 0.117, 0.061, 0.067, 0.106, -0.07, -0.15, -0.00, -0.14, 0.253, 0.048, 0.097, -0.00, 0.112, 0.053, 0.017, -0.05, -0.33, -0.09, 0.142, -0.13, 0.022, 0.100, -0.05, -0.15, -0.00, -0.09, -0.04, 0.085, 0.306, -0.11, -0.19, -0.20, 0.081, -0.04, -0.08, -0.10, 0.292, 0.023, -0.03, 0.035, -0.10, -0.06, 0.279, -0.11, -0.01, 0.384, -0.07, -0.02, -0.13, -0.05, -0.05, -0.08, -0.02, 0.083, 0.273, -0.06, -0.04, -0.01, -0.11, -0.10, 0.202, -0.12, -0.06, -0.26, 0.096, 0.104, -0.16, 0.055, 0.154, 0.080, 0.219, -0.22, 0.110, -0.00, -0.05, -0.09, -0.07, -0.03, 0.036, 0.158, -0.15, 0.226, 0.285, -0.05, 0.353, -0.12, 0.105, 0.031, -0.19, -0.23, -0.11, 0.002, 0.075, -0.01, 0.100, 0.445, -0.27, 0.066, -0.08, 0.063, 0.018, -0.11, 0.097, 0.206, -0.13, 0.023, 0.110, 0.080, -0.15, 0.004, 0.018, -0.09, -0.24, 0.083, -0.10, -0.15, 0.027, -0.16, -0.10, -0.00, 0.001, -0.25, 0.314, 0.131, -0.13, 0.021, -0.15, -0.14, -0.05, -0.12, -0.21, 0.031, 0.130, 0.097, 0.005, 0.022, 0.126, -0.01, 0.061, -0.02, 0.25, -0.07, 0.158, -0.07, 0.019, 0.008, -0.09, 0.363, -0.09, 0.024, -0.01, -0.05, 0.024, 0.005, -0.10, -0.00, 0.030, -0.07, -0.12, 0.038, 0.028, -0.22, -0.01, 0.154, 0.091, 0.105, -0.06, -0.12, -0.10, -0.02, -0.03, 0.074, 0.037, 0.074, -0.01, -0.04, 0.004, 0.103, -0.08, -0.22, -0.25, 0.035, 0.445, 0.055, 0.159, 0.271, -0.10, 0.062, -0.05, -0.25, -0.15, -0.06, -0.13, -0.15, -0.01, 0.021, 0.073, 0.130, -0.08, 0.029, 0.015, -0.16, 0.150, -0.00, 0.010, 0.114, -0.14, -0.04, -0.13, -0.17, -0.04, -0.05, 0.052, -0.11, 0.084, -0.02, 0.140, -0.18, 0.017, -0.13, -0.01, -0.01, 0.064, -0.28, -0.04, -0.19, -0.07, 0.064, -0.16, -0.02, -0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fSGkKsB4wmC",
        "colab_type": "text"
      },
      "source": [
        "## Define function to compute mean embedding vector of words in translated comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7gf_wJy5Ivv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_vector(comment):\n",
        "  \"\"\"returns mean of vector representation words in text.\n",
        "  returns a vector of zeros if none of the words appear in vocabulary \"\"\"\n",
        "  words = [w for w in comment.split() if w in vocabulary] # valid words\n",
        "  if not words: return np.zeros((embedding_size,), dtype=\"float32\") # no word  \n",
        "  return np.mean([word2vec[w] for w in words], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR_wBO4k6Xcx",
        "colab_type": "text"
      },
      "source": [
        "## Retreive pre-trained model for sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsGsuCFw6X4o",
        "colab_type": "code",
        "outputId": "4f5d405a-a8d0-4a65-a092-889f65ac99ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This model is a single layered neural network \n",
        "# trained using IMDB sentiment analysis data set.\n",
        "\n",
        "def getSAmodel(weights_file):\n",
        "  \"\"\"Returns trained single layered network\"\"\"\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(300,)),\n",
        "      tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  model.load_weights(weights_file)\n",
        "  return model\n",
        "\n",
        "weights_file = \"SA.model.weights.hdf5\" \n",
        "model = getSAmodel(weights_file)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPJlciWI7hD1",
        "colab_type": "text"
      },
      "source": [
        "## Define function to classify comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL_JjGFF75H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_polarity(comment):\n",
        "  \"\"\"returns sentiment polarity and mean vector for comment \"\"\"\n",
        "  mean_v = mean_vector(translate(comment))\n",
        "  return model.predict(np.array([mean_v]))[0][1], mean_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8aHZPU81wP0",
        "colab_type": "text"
      },
      "source": [
        "## Classify user specified comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySqWqo7i13z6",
        "colab_type": "code",
        "outputId": "b6077a0f-bc62-4700-fdb3-c6a447aaf701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "comment = input(\"Type in a comment:\") # input comment in any language\n",
        "score, _ = sentiment_polarity(comment) # compute polarity score\n",
        "sentiment = 'POSITIVE' if score > 0.5 else 'NEGATIVE'\n",
        "print(\"\\nYour comment: %s \\n\\texpresses a %s sentiment \\n\\t(score = %4.4f)\"\n",
        "     %(comment, sentiment, score))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type in a comment:I am worried that this boring workshop will drag on for another hour\n",
            "\n",
            "Your comment: I am worried that this boring workshop will drag on for another hour \n",
            "\texpresses a NEGATIVE sentiment \n",
            "\t(score = 0.0001)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}